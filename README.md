
# üí¨ PDF Chatbot using Local LLM (Ollama + LlamaIndex)

This project allows you to chat with one or more PDF documents **fully offline**, using **Ollama + LlamaIndex**. It supports **text-based** and **image-based (scanned)** PDFs by applying OCR automatically. It builds a searchable index using **local embeddings** and answers your questions in real time.

---

## üìÅ Project Structure
```
Project/
‚îú‚îÄ‚îÄ chatbot.py              # Chatbot interface using LlamaIndex & Ollama
‚îú‚îÄ‚îÄ ocrExtract.py           # Extracts text from PDFs (OCR fallback)
‚îú‚îÄ‚îÄ environment.yml         # Conda environment with all dependencies
‚îú‚îÄ‚îÄ data/                   # Put your PDF files here
‚îú‚îÄ‚îÄ extracted/pdf_text.txt  # Output of extracted text
‚îî‚îÄ‚îÄ index_store/            # Persistent vector index for fast reuse
```

---

## ‚úÖ Features

- üîç Supports both **text** and **scanned image** PDFs  
- üß† Uses **Ollama local models** like `llama3` or `mistral`  
- üì¶ Fully offline (no internet required)  
- ‚ôªÔ∏è Persistent vector index for fast reloading  
- üîí Runs in an isolated conda environment  
- üìä Embeddings & LLM both run locally  

---

## ‚öôÔ∏è Setup Instructions

### 1. Install Anaconda¬†or¬†Miniconda  
Download and install from the official site.

### 2. Create & activate the conda environment
```bash
conda env create -f environment.yml
conda activate myenv
```

### 3. Install & start Ollama
```bash
ollama serve &
ollama pull llama3     # or: ollama pull mistral
```

---

## üìù Processing PDFs
Put your PDF files inside **`data/`** and run:
```bash
python ocrExtract.py
```
This creates **`extracted/pdf_text.txt`**.

---

## üöÄ Start the Chatbot
```bash
python chatbot.py
```

Type questions, e.g.:
```
What penalties are mentioned in the SLA?
```
Type `exit` to quit.

---

## üîÑ Rebuild the Index
```bash
rm -r index_store/
python chatbot.py
```

---

## üõ† Command Cheat‚ÄëSheet
| Purpose                      | Command                                    |
|------------------------------|--------------------------------------------|
| Create env                   | `conda env create -f environment.yml`      |
| Activate env                 | `conda activate myenv`                     |
| Extract PDF text             | `python ocrExtract.py`                     |
| Start chatbot                | `python chatbot.py`                        |
| Pull new Ollama model        | `ollama pull mistral` (or any)             |
| Test model directly          | `ollama run mistral`                       |
| Stop Ollama server           | `pkill -f "ollama"`                        |

---

## üì¶ `environment.yml` (explained)
```yaml
name: myenv
channels:
  - conda-forge
dependencies:
  - python=3.11          # Base Python version
  - tesseract            # OCR engine backend
  - poppler              # PDF ‚Üí image conversion tools
  - libtiff              # Image codec dependency
  - pip
  - pip:
      - pytesseract                      # Python wrapper for Tesseract
      - pillow                           # Image handling (PIL)
      - pdf2image                        # Convert PDF pages to images
      - pymupdf                          # Fast PDF text extraction (`fitz`)
      - llama-index>=0.10.34             # Indexing & retrieval library
      - llama-index-llms-ollama          # LlamaIndex ‚Üî Ollama LLM connector
      - llama-index-embeddings-ollama    # Local embedding model via Ollama
      - ollama                           # Python client for Ollama
      - jupyter                          # Optional notebook support
```

---

## ‚ö†Ô∏è Troubleshooting
- **TypeError None √ó float** ‚Üí switch to `mistral` and upgrade `llama-index`.  
- **Timeout on first query** ‚Üí increase `request_timeout` in `chatbot.py` or pre‚Äëwarm: `ollama run model`.
